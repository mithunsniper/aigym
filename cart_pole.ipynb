{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    "This policy ensure that the pole attached to the cart remains staright throughtout without tilting to either left or right side of the pole. The cart is moved to the right if its state is lesser than the threshold value. The cart is moved to the left if its state is greater than the threshold value. If the pole angle and velocity increases in the positive direction the cart is moved to the right side. If the pole angle and velocity increases in the negative direction the cart is moved to the left side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol(obs):\n",
    "    #if the cart moves left do the move right action\n",
    "    if (obs[0] < -2):\n",
    "        return 1\n",
    "    #if the cart moves right do the move left action#\n",
    "    if (obs[0] > 2):\n",
    "        return 0\n",
    "    #if the pole angle and velocity increases in the positive direction move the cart to the right\n",
    "    if(obs[3]>0 and obs[2]>0 ):\n",
    "\n",
    "        return 1\n",
    "    #if the pole angle and velocity increases in the negative direction move the cart to the left\n",
    "    if (obs[3]<0 and obs[2] < 0):\n",
    "        return 0\n",
    "    return env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards obtained : [200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200.\n",
      " 200. 200. 200. 200. 200. 200.]\n",
      "Maximum  200.0 Minimum  200.0 Mean  200.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "reward_total=[]\n",
    "for i_episode in range(20):\n",
    "    obs = env.reset()\n",
    "\n",
    "    count=0\n",
    "    for t in range(200):\n",
    "        env.render()\n",
    "        \n",
    "        \n",
    "        action=pol(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        count=count+reward\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "\n",
    "            break\n",
    "    reward_total.append(count)\n",
    "\n",
    "reward_total=np.array(reward_total)\n",
    "print(\"Rewards obtained :\",reward_total)\n",
    "print(\"Maximum \",np.max(reward_total),\"Minimum \" ,np.min(reward_total),\"Mean \" ,np.mean(reward_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
